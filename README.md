# vLLM inference runtime
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Falialobidm%2Finference-engine-vllm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Falialobidm%2Finference-engine-vllm?ref=badge_shield)


This repo contains implementations of the vLLM inference runtime.



## License
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Falialobidm%2Finference-engine-vllm.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Falialobidm%2Finference-engine-vllm?ref=badge_large)